category: Analytics & SIEM
commonfields:
  id: SplunkPy
  version: -1
configuration:
- defaultvalue: ""
  display: Host - ip (x.x.x.x)
  name: host
  required: true
  type: 0
- defaultvalue: ""
  display: Username
  name: authentication
  required: true
  type: 9
- defaultvalue: "8089"
  display: Port
  name: port
  required: true
  type: 0
- defaultvalue: search index=notable | eval rule_name=if(isnull(rule_name),source,rule_name)
    | eval rule_title=if(isnull(rule_title),rule_name,rule_title) | `get_urgency`
    | `risk_correlation` | eval rule_description=if(isnull(rule_description),source,rule_description)
    | eval security_domain=if(isnull(security_domain),source,security_domain)
  display: Fetch notable events ES query
  name: fetchQuery
  required: false
  type: 0
- defaultvalue: "50"
  display: Fetch Limit (Max.- 200, Recommended less than 50)
  name: fetch_limit
  required: false
  type: 0
- defaultvalue: ""
  display: Fetch incidents
  name: isFetch
  required: false
  type: 8
- defaultvalue: ""
  display: Incident type
  name: incidentType
  required: false
  type: 13
- defaultvalue: ""
  display: Use system proxy settings
  name: proxy
  required: false
  type: 8
- defaultvalue: ""
  display: Timezone of the Splunk server, in minutes. For example, GMT is gmt +3,
    set +180 (set only if different than Demisto server). Relevant only for fetching
    notable events.
  name: timezone
  required: false
  type: 0
- defaultvalue: "false"
  display: Parse Raw part of notable events
  name: parseNotableEventsRaw
  required: false
  type: 8
- defaultvalue: ""
  display: Extract Fields - CSV fields that will be parsed out of _raw notable events
  name: extractFields
  required: false
  type: 12
- defaultvalue: "false"
  display: Use Splunk Clock Time For Fetch
  name: useSplunkTime
  required: false
  type: 8
- defaultvalue: ""
  display: Trust any certificate (not secure)
  name: unsecure
  required: false
  type: 8
- defaultvalue: index_earliest
  display: Earliest time to fetch (the name of the Splunk field whose value defines
    the query's earliest time to fetch)
  name: earliest_fetch_time_fieldname
  required: false
  type: 0
- defaultvalue: index_latest
  display: Latest time to fetch (the name of the Splunk field whose value defines
    the query's latest time to fetch)
  name: latest_fetch_time_fieldname
  required: false
  type: 0
- defaultvalue: ""
  display: The app context of the namespace
  name: app
  required: false
  type: 0
- defaultvalue: ""
  display: HEC Token (HTTP Event Collector)
  name: hec_token
  required: false
  type: 4
- defaultvalue: ""
  display: 'HEC URL (e.g: https://localhost:8088).'
  name: hec_url
  required: false
  type: 0
description: Run queries on Splunk servers.
detaileddescription: |
  Use the SplunkPy integration to fetch incidents from Splunk ES, and query results by SID.
display: SplunkPy
image: data:image/png;base64,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
name: SplunkPy
script:
  commands:
  - arguments:
    - default: true
      description: ID of the search for which to return results.
      name: sid
      required: true
    description: Returns the results of a previous Splunk search. You can use this
      command in conjunction with the splunk-job-create command.
    name: splunk-results
  - arguments:
    - default: true
      description: 'The Splunk search language string to execute. For example: "index=*
        | head 3". '
      name: query
      required: true
    - description: 'Specifies the earliest time in the time range to search. The time
        string can be a UTC time (with fractional seconds), a relative time specifier
        (to now), or a formatted time string. Default is 1 week ago, in the format
        "-7d". You can also specify time in the format: 2014-06-19T12:00:00.000-07:00"'
      name: earliest_time
    - description: ' Specifies the latest time in the time range to search. The time
        string can be a UTC time (with fractional seconds), a relative time specifier
        (to now), or a formatted time string. For example: "2014-06-19T12:00:00.000-07:00"
        or "-3d" (for time 3 days before now)'
      name: latest_time
    - description: Maximum number of events to return. Default is 100. If "0", all
        results are returned.
      name: event_limit
    - defaultValue: "25000"
      description: The maximum number of returned results to  process at a time. For
        example, if 100 results are returned, and you specify a batch_limit of 10,
        the results will be processed 10 at a time over 10 iterations. This does not
        effect the search or the context and outputs returned. In some cases, specifying
        a batch_size enhances search performance. If you think that the search execution
        is suboptimal, we recommend trying several batch_size values to determine
        which works best for your search. Default is 25,000.
      name: batch_limit
    - auto: PREDEFINED
      defaultValue: "true"
      description: Determines whether the results will be entered into the context.
      name: update_context
      predefined:
      - "true"
      - "false"
    - description: A string that contains the application namespace in which to restrict
        searches.
      name: app
    description: Searches Splunk for events.
    name: splunk-search
    outputs:
    - contextPath: Splunk.Result
      description: The results of the Splunk search. The results are a JSON array,
        in which each item is a Splunk event.
      type: Unknown
  - arguments:
    - description: Splunk index to which to push data. Run the splunk-get-indexes
        command to get all indexes.
      name: index
      required: true
    - default: true
      description: The new event data to push, can be any string.
      name: data
      required: true
    - description: Event source type.
      name: sourcetype
      required: true
    - description: Event host. Can be "Local" or "120.0.0.1".
      name: host
      required: true
    description: Creates a new event in Splunk.
    name: splunk-submit-event
  - arguments: []
    description: Prints all Splunk index names.
    name: splunk-get-indexes
  - arguments:
    - description: A comma-separated list of event IDs of notable events.
      name: eventIDs
      required: true
    - description: A Splunk user to assign to the notable event.
      name: owner
    - description: Comment to add to the notable event.
      name: comment
      required: true
    - auto: PREDEFINED
      description: Notable event urgency.
      name: urgency
      predefined:
      - critical
      - high
      - medium
      - low
      - informational
    - description: Notable event status. 0 - Unassigned, 1 - Assigned, 2 - In Progress,
        3 - Pending, 4 - Resolved, 5 - Closed.
      name: status
    description: Update an existing Notable event in Splunk ES
    execution: true
    name: splunk-notable-event-edit
  - arguments:
    - description: The Splunk search language string to execute. For example :"index=*
        | head 3".
      name: query
      required: true
    - description: A string that contains the application namespace in which to restrict
        searches.
      name: app
    description: Creates a new search job in Splunk.
    name: splunk-job-create
    outputs:
    - contextPath: Splunk.Job
      description: The SID of the created job.
      type: Unknown
  - arguments:
    - default: true
      defaultValue: ${Splunk.Result._raw}
      description: The raw data of the Splunk event (string).
      name: raw
    description: Parses the raw part of the event.
    name: splunk-parse-raw
    outputs:
    - contextPath: Splunk.Raw.Parsed
      description: The raw event data (parsed).
      type: unknown
  - arguments:
    - description: |-
        Event payload key-value.
        String example: "event": "Access log test message."
      name: event
      required: true
    - description: Fields for indexing that do not occur in the event payload itself.
        Accepts multiple comma separated fields.
      name: fields
    - description: The index name.
      name: index
    - description: The hostname.
      name: host
    - description: User-defined event source type.
      name: source_type
    - description: User-defined event source.
      name: source
    - description: Epoch-formatted time
      name: time
    description: Sends events to an HTTP Event Collector using the Splunk platform
      JSON event protocol.
    name: splunk-submit-event-hec
  dockerimage: demisto/splunksdk:1.0
  isfetch: true
  runonce: false
  script: |2


    import splunklib.client as client
    import splunklib.results as results
    import json
    from datetime import timedelta, datetime
    import urllib2
    import ssl
    from StringIO import StringIO
    import requests
    import urllib3
    import io
    import re

    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    # Define utf8 as default encoding
    reload(sys)
    sys.setdefaultencoding('utf8')  # pylint: disable=maybe-no-member

    SPLUNK_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"
    VERIFY_CERTIFICATE = not bool(demisto.params().get('unsecure'))
    FETCH_LIMIT = int(demisto.params().get('fetch_limit', 50))
    FETCH_LIMIT = max(min(200, FETCH_LIMIT), 1)


    class ResponseReaderWrapper(io.RawIOBase):
        """ This class was supplied as a solution for a bug in Splunk causing the search to run slowly.
        """

        def __init__(self, responseReader):
            self.responseReader = responseReader

        def readable(self):
            return True

        def close(self):
            self.responseReader.close()

        def read(self, n):
            return self.responseReader.read(n)

        def readinto(self, b):
            sz = len(b)
            data = self.responseReader.read(sz)
            for idx, ch in enumerate(data):
                b[idx] = ch

            return len(data)


    def get_current_splunk_time(splunk_service):
        t = datetime.utcnow() - timedelta(days=3)
        time = t.strftime(SPLUNK_TIME_FORMAT)
        kwargs_oneshot = {'count': 1, 'earliest_time': time}
        searchquery_oneshot = '| gentimes start=-1 | eval clock = strftime(time(), "%Y-%m-%dT%H:%M:%S")' \
                              ' | sort 1 -_time | table clock'

        oneshotsearch_results = splunk_service.jobs.oneshot(searchquery_oneshot, **kwargs_oneshot)

        reader = results.ResultsReader(oneshotsearch_results)
        for item in reader:
            if isinstance(item, results.Message):
                return item.message["clock"]
            if isinstance(item, dict):
                return item["clock"]
        raise ValueError('Error: Could not fetch Splunk time')


    def rawToDict(raw):
        result = {}  # type: Dict[str, str]
        if 'message' in raw:
            raw = raw.replace('"', '').strip('{').strip('}')
            key_val_arr = raw.split(",")
            for key_val in key_val_arr:
                single_key_val = key_val.split(":")
                if len(single_key_val) > 1:
                    val = single_key_val[1]
                    key = single_key_val[0].strip()

                    if key in result.keys():
                        result[key] = result[key] + "," + val
                    else:
                        result[key] = val

        else:
            raw_response = re.split('(?<=\S),', raw)  # split by any non-whitespace character
            for key_val in raw_response:
                key_value = key_val.replace('"', '').strip()
                if '=' in key_value:
                    key_and_val = key_value.split('=', 1)
                    result[key_and_val[0]] = key_and_val[1]
        return result


    # Converts to an str
    def convert_to_str(obj):
        if isinstance(obj, unicode):
            return obj.encode('utf-8')
        return str(obj)


    def updateNotableEvents(sessionKey, baseurl, comment, status=None, urgency=None, owner=None, eventIDs=None,
                            searchID=None):
        """
        Update some notable events.

        Arguments:
        sessionKey -- The session key to use
        comment -- A description of the change or some information about the notable events
        status -- A status (only required if you are changing the status of the event)
        urgency -- An urgency (only required if you are changing the urgency of the event)
        owner -- A nowner (only required if reassigning the event)
        eventIDs -- A list of notable event IDs (must be provided if a search ID is not provided)
        searchID -- An ID of a search. All of the events associated with this search will be modified
         unless a list of eventIDs are provided that limit the scope to a sub-set of the results.
        """

        # Make sure that the session ID was provided
        if sessionKey is None:
            raise Exception("A session key was not provided")

        # Make sure that rule IDs and/or a search ID is provided
        if eventIDs is None and searchID is None:
            raise Exception("Either eventIDs of a searchID must be provided (or both)")
            return False

        # These the arguments to the REST handler
        args = {}
        args['comment'] = comment

        if status is not None:
            args['status'] = status

        if urgency is not None:
            args['urgency'] = urgency

        if owner is not None:
            args['newOwner'] = owner

        # Provide the list of event IDs that you want to change:
        if eventIDs is not None:
            args['ruleUIDs'] = eventIDs

        # If you want to manipulate the notable events returned by a search then include the search ID
        if searchID is not None:
            args['searchID'] = searchID

        auth_header = {'Authorization': 'Splunk %s' % sessionKey}

        args['output_mode'] = 'json'

        mod_notables = requests.post(baseurl + 'services/notable_update', data=args, headers=auth_header,
                                     verify=VERIFY_CERTIFICATE)

        return mod_notables.json()


    def severity_to_level(severity):
        if severity == 'informational':
            return 0.5
        elif severity == 'critical':
            return 4
        elif severity == 'high':
            return 3
        elif severity == 'medium':
            return 2
        else:
            return 1


    def notable_to_incident(event):
        incident = {}  # type: Dict[str,Any]
        rule_title = ''
        rule_name = ''
        if demisto.get(event, 'rule_title'):
            rule_title = event['rule_title']
        if demisto.get(event, 'rule_name'):
            rule_name = event['rule_name']
        incident["name"] = "{} : {}".format(rule_title, rule_name)
        if demisto.get(event, 'urgency'):
            incident["severity"] = severity_to_level(event['urgency'])
        if demisto.get(event, 'rule_description'):
            incident["details"] = event["rule_description"]
        if demisto.get(event, "_time"):
            incident["occurred"] = event["_time"]
        else:
            incident["occurred"] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S.0+00:00')
        incident["rawJSON"] = json.dumps(event)
        labels = []
        if demisto.get(demisto.params(), 'parseNotableEventsRaw'):
            isParseNotableEventsRaw = demisto.params()['parseNotableEventsRaw']
            if isParseNotableEventsRaw:
                rawDict = rawToDict(event['_raw'])
                for rawKey in rawDict:
                    labels.append({'type': rawKey, 'value': rawDict[rawKey]})
        if demisto.get(event, 'security_domain'):
            labels.append({'type': 'security_domain', 'value': event["security_domain"]})
        incident['labels'] = labels
        return incident


    def handler(proxy):
        proxy_handler = urllib2.ProxyHandler({'http': proxy, 'https': proxy})
        opener = urllib2.build_opener(proxy_handler)
        urllib2.install_opener(opener)
        return request


    def request(url, message, **kwargs):
        method = message['method'].lower()
        data = message.get('body', "") if method == 'post' else None
        headers = dict(message.get('headers', []))
        req = urllib2.Request(url, data, headers)  # guardrails-disable-line
        context = ssl.create_default_context()

        if VERIFY_CERTIFICATE:
            context.verify_mode = ssl.CERT_REQUIRED
        else:
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE

        try:
            response = urllib2.urlopen(req, context=context)  # guardrails-disable-line
        except urllib2.HTTPError as response:
            pass  # Propagate HTTP errors via the returned response message
        return {
            'status': response.code,  # type: ignore
            'reason': response.msg,  # type: ignore
            'headers': response.info().dict,  # type: ignore
            'body': StringIO(response.read())  # type: ignore
        }


    def build_search_kwargs(args):
        t = datetime.utcnow() - timedelta(days=7)
        time_str = t.strftime(SPLUNK_TIME_FORMAT)

        kwargs_normalsearch = {
            "earliest_time": time_str,
            "exec_mode": "blocking"  # A blocking search runs synchronously, and returns a job when it's finished.
        }  # type: Dict[str,Any]
        if demisto.get(args, 'earliest_time'):
            kwargs_normalsearch['earliest_time'] = args['earliest_time']
        if demisto.get(args, 'latest_time'):
            kwargs_normalsearch['latest_time'] = args['latest_time']
        if demisto.get(args, 'app'):
            kwargs_normalsearch['app'] = args['app']
        return kwargs_normalsearch


    def build_search_query(args):
        query = args['query']
        query = query.encode('utf-8')
        if not query.startswith('search') and not query.startswith('Search') and not query.startswith('|'):
            query = 'search ' + query
        return query


    def create_entry_context(args, parsed_search_results, dbot_scores):
        ec = {}

        if args.get('update_context', "true") == "true":
            ec['Splunk.Result'] = parsed_search_results
            if len(dbot_scores) > 0:
                ec['DBotScore'] = dbot_scores
        return ec


    def build_search_human_readable(args, parsed_search_results):
        headers = ""
        if parsed_search_results and len(parsed_search_results) > 0:
            if not isinstance(parsed_search_results[0], dict):
                headers = "results"

        human_readable = tableToMarkdown("Splunk Search results for query: {}".format(args['query']),
                                         parsed_search_results, headers)
        return human_readable


    def get_current_results_batch(search_job, batch_size, results_offset):
        current_batch_kwargs = {
            "count": batch_size,
            "offset": results_offset
        }

        results_batch = search_job.results(**current_batch_kwargs)
        return results_batch


    def parse_batch_of_results(current_batch_of_results, max_results_to_add, app):
        parsed_batch_results = []
        batch_dbot_scores = []
        results_reader = results.ResultsReader(io.BufferedReader(ResponseReaderWrapper(current_batch_of_results)))
        for item in results_reader:
            if isinstance(item, results.Message):
                if "Error in" in item.message:
                    raise ValueError(item.message)
                parsed_batch_results.append(convert_to_str(item.message))

            elif isinstance(item, dict):
                if demisto.get(item, 'host'):
                    batch_dbot_scores.append({'Indicator': item['host'], 'Type': 'hostname',
                                              'Vendor': 'Splunk', 'Score': 0, 'isTypedIndicator': True})
                if app:
                    item['app'] = app
                # Normal events are returned as dicts
                parsed_batch_results.append(item)

            if len(parsed_batch_results) >= max_results_to_add:
                break
        return parsed_batch_results, batch_dbot_scores


    def splunk_search_command(service):
        args = demisto.args()

        query = build_search_query(args)
        search_kwargs = build_search_kwargs(args)
        search_job = service.jobs.create(query, **search_kwargs)  # type: ignore
        num_of_results_from_query = search_job["resultCount"]

        results_limit = float(demisto.args().get("event_limit", 100))
        if results_limit == 0.0:
            # In Splunk, a result limit of 0 means no limit.
            results_limit = float("inf")
        batch_size = int(demisto.args().get("batch_limit", 25000))

        results_offset = 0
        total_parsed_results = []  # type: List[Dict[str,Any]]
        dbot_scores = []  # type: List[Dict[str,Any]]

        while len(total_parsed_results) < int(num_of_results_from_query) and len(total_parsed_results) < results_limit:
            current_batch_of_results = get_current_results_batch(search_job, batch_size, results_offset)
            max_results_to_add = results_limit - len(total_parsed_results)
            parsed_batch_results, batch_dbot_scores = parse_batch_of_results(current_batch_of_results, max_results_to_add,
                                                                             search_kwargs.get('app', ''))
            total_parsed_results.extend(parsed_batch_results)
            dbot_scores.extend(batch_dbot_scores)

            results_offset += batch_size

        entry_context = create_entry_context(args, total_parsed_results, dbot_scores)
        human_readable = build_search_human_readable(args, total_parsed_results)

        demisto.results({
            "Type": 1,
            "Contents": total_parsed_results,
            "ContentsFormat": "json",
            "EntryContext": entry_context,
            "HumanReadable": human_readable
        })


    def splunk_job_create_command(service):
        query = demisto.args()['query']
        app = demisto.args().get('app', '')
        if not query.startswith('search'):
            query = 'search ' + query
        search_kwargs = {
            "exec_mode": "normal",
            "app": app
        }
        search_job = service.jobs.create(query, **search_kwargs)  # type: ignore

        entry_context = {
            'Splunk.Job': search_job.sid
        }
        demisto.results({
            "Type": 1,
            "ContentsFormat": formats['text'],
            "Contents": "Splunk Job created with SID: " + search_job.sid,
            "EntryContext": entry_context
        })


    def splunk_results_command(service):
        jobs = service.jobs  # type: ignore
        found = False
        res = []
        for job in jobs:
            if job.sid == demisto.args()['sid']:
                rr = results.ResultsReader(job.results())
                for result in rr:
                    if isinstance(result, results.Message):
                        demisto.results({"Type": 1, "ContentsFormat": "json", "Contents": json.dumps(result.message)})
                    elif isinstance(result, dict):
                        # Normal events are returned as dicts
                        res.append(result)
                found = True
        if not found:
            demisto.results("Found no job for sid: " + demisto.args()['sid'])
        if found:
            demisto.results({"Type": 1, "ContentsFormat": "json", "Contents": json.dumps(res)})


    def fetch_incidents(service):
        lastRun = demisto.getLastRun() and demisto.getLastRun()['time']
        search_offset = demisto.getLastRun().get('offset', 0)

        incidents = []
        t = datetime.utcnow()
        if demisto.get(demisto.params(), 'timezone'):
            timezone = demisto.params()['timezone']
            t = t + timedelta(minutes=int(timezone))

        now = t.strftime(SPLUNK_TIME_FORMAT)
        if demisto.get(demisto.params(), 'useSplunkTime'):
            now = get_current_splunk_time(service)
            t = datetime.strptime(now, SPLUNK_TIME_FORMAT)
        if len(lastRun) == 0:
            t = t - timedelta(minutes=10)
            lastRun = t.strftime(SPLUNK_TIME_FORMAT)

        earliest_fetch_time_fieldname = demisto.params().get("earliest_fetch_time_fieldname", "index_earliest")
        latest_fetch_time_fieldname = demisto.params().get("latest_fetch_time_fieldname", "index_latest")

        kwargs_oneshot = {earliest_fetch_time_fieldname: lastRun,
                          latest_fetch_time_fieldname: now, "count": FETCH_LIMIT, 'offset': search_offset}

        searchquery_oneshot = demisto.params()['fetchQuery']

        if demisto.get(demisto.params(), 'extractFields'):
            extractFields = demisto.params()['extractFields']
            extra_raw_arr = extractFields.split(',')
            for field in extra_raw_arr:
                field_trimmed = field.strip()
                searchquery_oneshot = searchquery_oneshot + ' | eval ' + field_trimmed + '=' + field_trimmed

        oneshotsearch_results = service.jobs.oneshot(searchquery_oneshot, **kwargs_oneshot)  # type: ignore
        reader = results.ResultsReader(oneshotsearch_results)
        for item in reader:
            inc = notable_to_incident(item)
            incidents.append(inc)

        demisto.incidents(incidents)
        if len(incidents) < FETCH_LIMIT:
            demisto.setLastRun({'time': now, 'offset': 0})
        else:
            demisto.setLastRun({'time': lastRun, 'offset': search_offset + FETCH_LIMIT})


    def splunk_get_indexes_command(service):
        indexes = service.indexes  # type: ignore
        indexesNames = []
        for index in indexes:
            index_json = {'name': index.name, 'count': index["totalEventCount"]}
            indexesNames.append(index_json)
        demisto.results({"Type": 1, "ContentsFormat": "json", "Contents": json.dumps(indexesNames),
                         'HumanReadable': tableToMarkdown("Splunk Indexes names", indexesNames, '')})


    def splunk_submit_event_command(service):
        try:
            index = service.indexes[demisto.args()['index']]  # type: ignore
        except KeyError:
            demisto.results({'ContentsFormat': formats['text'], 'Type': entryTypes['error'],
                             'Contents': "Found no Splunk index: " + demisto.args()['index']})

        else:
            data = demisto.args()['data']
            data_formatted = data.encode('utf8')
            r = index.submit(data_formatted, sourcetype=demisto.args()['sourcetype'], host=demisto.args()['host'])
            demisto.results('Event was created in Splunk index: ' + r.name)


    def splunk_submit_event_hec(hec_token, baseurl, event, fields, host, index, source_type, source, time_):

        if hec_token is None:
            raise Exception('The HEC Token was not provided')

        args = assign_params(
            event=event,
            host=host,
            fields={'fields': fields} if fields else None,
            index=index,
            sourcetype=source_type,
            source=source,
            time=time_
        )

        headers = {
            'Authorization': 'Splunk {}'.format(hec_token),
            'Content-Type': 'application/json'
        }

        response = requests.post(baseurl + '/services/collector/event', data=json.dumps(args), headers=headers,
                                 verify=VERIFY_CERTIFICATE)
        return response


    def splunk_submit_event_hec_command():

        hec_token = demisto.params().get('hec_token')
        baseurl = demisto.params().get('hec_url')
        if baseurl is None:
            raise Exception('The HEC URL was not provided.')

        event = demisto.args().get('event')
        host = demisto.args().get('host')
        fields = demisto.args().get('fields')
        index = demisto.args().get('index')
        source_type = demisto.args().get('source_type')
        source = demisto.args().get('source')
        time_ = demisto.args().get('time')

        response_info = splunk_submit_event_hec(hec_token, baseurl, event, fields, host, index, source_type, source, time_)

        if 'Success' not in response_info.text:
            return_error('Could not send event to Splunk ' + response_info.text.encode('utf8'))
        else:
            demisto.results('The event was sent successfully to Splunk.')


    def splunk_edit_notable_event_command(proxy):
        if not proxy:
            os.environ["HTTPS_PROXY"] = ""
            os.environ["HTTP_PROXY"] = ""
            os.environ["https_proxy"] = ""
            os.environ["http_proxy"] = ""
        baseurl = 'https://' + demisto.params()['host'] + ':' + demisto.params()['port'] + '/'
        username = demisto.params()['authentication']['identifier']
        password = demisto.params()['authentication']['password']
        auth_req = requests.post(baseurl + 'services/auth/login',
                                 data={'username': username, 'password': password, 'output_mode': 'json'},
                                 verify=VERIFY_CERTIFICATE)

        sessionKey = auth_req.json()['sessionKey']
        eventIDs = None
        if demisto.get(demisto.args(), 'eventIDs'):
            eventIDsStr = demisto.args()['eventIDs']
            eventIDs = eventIDsStr.split(",")
        status = None
        if demisto.get(demisto.args(), 'status'):
            status = int(demisto.args()['status'])
        response_info = updateNotableEvents(sessionKey=sessionKey, baseurl=baseurl,
                                            comment=demisto.get(demisto.args(), 'comment'), status=status,
                                            urgency=demisto.get(demisto.args(), 'urgency'),
                                            owner=demisto.get(demisto.args(), 'owner'), eventIDs=eventIDs)
        if 'success' not in response_info or not response_info['success']:
            demisto.results({'ContentsFormat': formats['text'], 'Type': entryTypes['error'],
                             'Contents': "Could not update notable "
                                         "events: " + demisto.args()['eventIDs'] + ' : ' + str(response_info)})

        demisto.results('Splunk ES Notable events: ' + response_info['message'])


    def splunk_parse_raw_command():
        raw = demisto.args().get('raw', '')
        rawDict = rawToDict(raw)
        ec = {}
        ec['Splunk.Raw.Parsed'] = rawDict
        demisto.results({"Type": 1, "ContentsFormat": "json", "Contents": json.dumps(rawDict), "EntryContext": ec})


    def test_module(service):
        if demisto.params().get('isFetch'):
            t = datetime.utcnow() - timedelta(days=3)
            time = t.strftime(SPLUNK_TIME_FORMAT)
            kwargs_oneshot = {'count': 1, 'earliest_time': time}
            searchquery_oneshot = demisto.params()['fetchQuery']
            oneshotsearch_results = service.jobs.oneshot(searchquery_oneshot, **kwargs_oneshot)  # type: ignore
            reader = results.ResultsReader(oneshotsearch_results)
            for item in reader:
                if item:
                    demisto.results('ok')

        if len(service.jobs) >= 0:  # type: ignore
            demisto.results('ok')


    def main():
        service = None
        proxy = demisto.params().get('proxy')
        if proxy:
            try:
                service = client.connect(
                    handler=handler(proxy),
                    host=demisto.params()['host'],
                    port=demisto.params()['port'],
                    app=demisto.params().get('app'),
                    username=demisto.params()['authentication']['identifier'],
                    password=demisto.params()['authentication']['password'],
                    verify=VERIFY_CERTIFICATE)
            except urllib2.URLError as e:
                if e.reason.errno == 1 and sys.version_info < (2, 6, 3):  # type: ignore
                    pass
                else:
                    raise
        else:
            service = client.connect(
                host=demisto.params()['host'],
                port=demisto.params()['port'],
                app=demisto.params().get('app'),
                username=demisto.params()['authentication']['identifier'],
                password=demisto.params()['authentication']['password'],
                verify=VERIFY_CERTIFICATE)

        if service is None:
            demisto.error("Could not connect to SplunkPy")

        # The command demisto.command() holds the command sent from the user.
        if demisto.command() == 'test-module':
            test_module(service)
        if demisto.command() == 'splunk-search':
            splunk_search_command(service)
        if demisto.command() == 'splunk-job-create':
            splunk_job_create_command(service)
        if demisto.command() == 'splunk-results':
            splunk_results_command(service)
        if demisto.command() == 'fetch-incidents':
            fetch_incidents(service)
        if demisto.command() == 'splunk-get-indexes':
            splunk_get_indexes_command(service)
        if demisto.command() == 'splunk-submit-event':
            splunk_submit_event_command(service)
        if demisto.command() == 'splunk-notable-event-edit':
            splunk_edit_notable_event_command(proxy)
        if demisto.command() == 'splunk-parse-raw':
            splunk_parse_raw_command()
        if demisto.command() == 'splunk-submit-event-hec':
            splunk_submit_event_hec_command()


    if __name__ in ['__main__', '__builtin__', 'builtins']:
        main()
  subtype: python2
  type: python
system: true
